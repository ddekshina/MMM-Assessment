{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6282b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "df = pd.read_csv(\"../data/Assessment 2 - MMM Weekly.csv\")\n",
    "\n",
    "# show first few rows\n",
    "print(df.head())\n",
    "\n",
    "# check columns\n",
    "print(df.columns)\n",
    "\n",
    "# check missing values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cee03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure week is datetime and sorted\n",
    "df['week'] = pd.to_datetime(df['week'])\n",
    "df = df.sort_values('week')\n",
    "\n",
    "# Plot revenue over time\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df['week'], df['revenue'], marker='o')\n",
    "plt.title(\"Revenue over Time\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick spend columns\n",
    "spend_cols = ['facebook_spend', 'google_spend', 'tiktok_spend', \n",
    "              'instagram_spend', 'snapchat_spend']\n",
    "\n",
    "# Plot each spend channel vs revenue\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i, col in enumerate(spend_cols, 1):\n",
    "    plt.subplot(len(spend_cols), 1, i)\n",
    "    plt.plot(df['week'], df[col], label=col, color='tab:blue')\n",
    "    plt.plot(df['week'], df['revenue'], label='revenue', color='tab:orange', alpha=0.7)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel(col)\n",
    "    if i == 1:\n",
    "        plt.title(\"Spend channels vs Revenue over time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(12,8), sharex=True)\n",
    "\n",
    "axs[0].plot(df['week'], df['promotions'], label='promotions', color='purple')\n",
    "axs[0].plot(df['week'], df['revenue'], label='revenue', color='orange', alpha=0.7)\n",
    "axs[0].legend(loc='upper right')\n",
    "\n",
    "axs[1].plot(df['week'], df['emails_send'], label='emails', color='green')\n",
    "axs[1].plot(df['week'], df['revenue'], label='revenue', color='orange', alpha=0.7)\n",
    "axs[1].legend(loc='upper right')\n",
    "\n",
    "axs[2].plot(df['week'], df['sms_send'], label='sms', color='red')\n",
    "axs[2].plot(df['week'], df['revenue'], label='revenue', color='orange', alpha=0.7)\n",
    "axs[2].legend(loc='upper right')\n",
    "\n",
    "axs[3].plot(df['week'], df['average_price'], label='average_price', color='blue')\n",
    "axs[3].plot(df['week'], df['revenue'], label='revenue', color='orange', alpha=0.7)\n",
    "axs[3].legend(loc='upper right')\n",
    "\n",
    "plt.suptitle(\"Other Marketing Levers vs Revenue\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Features and target\n",
    "X = df[['facebook_spend','google_spend','tiktok_spend',\n",
    "        'instagram_spend','snapchat_spend',\n",
    "        'emails_send','sms_send','social_followers',\n",
    "        'average_price','promotions']]\n",
    "\n",
    "y = df['revenue']\n",
    "\n",
    "# Train-test split (time-based: first 80% train, last 20% test)\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "# Compare actual vs predicted visually\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test.index, y_test.values, label=\"Actual\")\n",
    "plt.plot(y_test.index, y_pred, label=\"Predicted\")\n",
    "plt.title(\"Baseline Linear Regression: Revenue (Test Set)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e342e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def adstock(series, half_life=2):\n",
    "    \"\"\"\n",
    "    Simple exponential adstock transform.\n",
    "    half_life = weeks until effect halves.\n",
    "    \"\"\"\n",
    "    decay = 0.5 ** (1/half_life)\n",
    "    res = np.zeros(len(series))\n",
    "    carry = 0\n",
    "    for i, x in enumerate(series):\n",
    "        carry = x + decay * carry\n",
    "        res[i] = carry\n",
    "    return res\n",
    "\n",
    "# Apply adstock to each spend channel\n",
    "spend_cols = ['facebook_spend','google_spend','tiktok_spend',\n",
    "              'instagram_spend','snapchat_spend']\n",
    "\n",
    "for col in spend_cols:\n",
    "    df[col + \"_adstock\"] = adstock(df[col].values, half_life=2)\n",
    "\n",
    "# Check first few rows\n",
    "df[[col+\"_adstock\" for col in spend_cols]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transform to adstocked spends\n",
    "for col in spend_cols:\n",
    "    ad_col = col + \"_adstock\"\n",
    "    sat_col = col + \"_sat\"\n",
    "    df[sat_col] = np.log1p(df[ad_col])   # log1p = log(1+x), safe for zero\n",
    "\n",
    "# Check new saturation columns\n",
    "df[[col+\"_sat\" for col in spend_cols]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Features: saturated spends + controls\n",
    "X = df[[col+\"_sat\" for col in spend_cols] + \n",
    "       ['emails_send','sms_send','social_followers','average_price','promotions']]\n",
    "\n",
    "y = df['revenue']\n",
    "\n",
    "# Train-test split (time-based: first 80% train, last 20% test)\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test.index, y_test.values, label=\"Actual\")\n",
    "plt.plot(y_test.index, y_pred, label=\"Predicted\")\n",
    "plt.title(\"Improved Linear Regression: Revenue (with Adstock + Saturation)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Social channels (use the same ones you had before with adstock/saturation if available)\n",
    "social_features = ['facebook_spend_sat', 'tiktok_spend_sat', 'snapchat_spend_sat', 'instagram_spend_sat']\n",
    "\n",
    "# Controls (non-media factors)\n",
    "controls = ['emails_send','sms_send','social_followers','average_price','promotions']\n",
    "\n",
    "# Stage 1: Google ~ social + controls\n",
    "X_stage1 = df[social_features + controls]\n",
    "y_stage1 = df['google_spend']\n",
    "\n",
    "model_stage1 = LinearRegression()\n",
    "model_stage1.fit(X_stage1, y_stage1)\n",
    "\n",
    "# Print coefficients\n",
    "coef_stage1 = pd.Series(model_stage1.coef_, index=X_stage1.columns)\n",
    "print(\"Stage1 coefficients (Google ~ Social + Controls):\")\n",
    "print(coef_stage1.sort_values(ascending=False).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7601229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 predictions: predicted Google spend\n",
    "df['google_hat'] = model_stage1.predict(X_stage1)\n",
    "\n",
    "# Stage 2: Revenue ~ social + predicted Google + controls\n",
    "X_stage2 = df[social_features + ['google_hat'] + controls]\n",
    "y_stage2 = df['revenue']\n",
    "\n",
    "model_stage2 = LinearRegression()\n",
    "model_stage2.fit(X_stage2, y_stage2)\n",
    "\n",
    "# Print coefficients\n",
    "coef_stage2 = pd.Series(model_stage2.coef_, index=X_stage2.columns)\n",
    "print(\"Stage2 coefficients (Revenue ~ Social + Predicted Google + Controls):\")\n",
    "print(coef_stage2.sort_values(ascending=False).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ee1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indirect effect for social i = (coef_stage1[social_i]) * (coef_stage2['google_hat'])\n",
    "indirect_multiplier = coef_stage2['google_hat']\n",
    "\n",
    "effects = []\n",
    "for s in social_features:\n",
    "    direct = coef_stage2.get(s, 0.0)\n",
    "    indirect = coef_stage1.get(s, 0.0) * indirect_multiplier\n",
    "    total = direct + indirect\n",
    "    pct_indirect = (indirect / total) if total != 0 else np.nan\n",
    "    effects.append({\n",
    "        \"channel\": s,\n",
    "        \"direct\": direct,\n",
    "        \"indirect\": indirect,\n",
    "        \"total\": total,\n",
    "        \"pct_indirect\": pct_indirect\n",
    "    })\n",
    "\n",
    "effects_df = pd.DataFrame(effects)\n",
    "print(\"Direct vs Indirect vs Total effects:\")\n",
    "print(effects_df.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def rolling_origin_eval(X, y, n_splits=5, initial_train_size=None):\n",
    "    n = len(X)\n",
    "    if initial_train_size is None:\n",
    "        initial_train_size = int(n * 0.5)\n",
    "    fold_size = int((n - initial_train_size) / n_splits)\n",
    "    results = []\n",
    "    for i in range(n_splits):\n",
    "        train_end = initial_train_size + i * fold_size\n",
    "        test_start = train_end\n",
    "        test_end = min(train_end + fold_size, n)\n",
    "        if test_start >= test_end:\n",
    "            continue\n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(X.iloc[:train_end], y.iloc[:train_end])\n",
    "        y_pred = model.predict(X.iloc[test_start:test_end])\n",
    "        rmse = mean_squared_error(y.iloc[test_start:test_end], y_pred) ** 0.5\n",
    "        r2 = r2_score(y.iloc[test_start:test_end], y_pred)\n",
    "        results.append({\"fold\": i+1, \"rmse\": rmse, \"r2\": r2})\n",
    "    return results\n",
    "\n",
    "X_stage2 = df[social_features + ['google_hat'] + controls]\n",
    "y_stage2 = df['revenue']\n",
    "\n",
    "cv_results = rolling_origin_eval(X_stage2, y_stage2, n_splits=5, initial_train_size=int(len(df)*0.5))\n",
    "print(\"Rolling CV results:\")\n",
    "for r in cv_results:\n",
    "    print(f\" Fold {r['fold']}: RMSE={r['rmse']:.2f}, R²={r['r2']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit on first 80% for diagnostics\n",
    "split = int(len(df) * 0.8)\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_stage2.iloc[:split], y_stage2.iloc[:split])\n",
    "y_pred = model.predict(X_stage2.iloc[split:])\n",
    "resid = y_stage2.iloc[split:] - y_pred\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Residuals vs predictions\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(y_pred, resid)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xlabel(\"Predicted revenue\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predictions (holdout)\")\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation of residuals\n",
    "plot_acf(resid, lags=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lagged revenue features\n",
    "df['revenue_lag1'] = df['revenue'].shift(1)\n",
    "df['revenue_lag2'] = df['revenue'].shift(2)\n",
    "\n",
    "# Drop first 2 rows (they have NaNs from shifting)\n",
    "df_lagged = df.dropna().copy()\n",
    "\n",
    "# Update features to include lagged revenue\n",
    "X_stage2_lag = df_lagged[social_features + ['google_hat'] + controls + ['revenue_lag1','revenue_lag2']]\n",
    "y_stage2_lag = df_lagged['revenue']\n",
    "\n",
    "# Refit model\n",
    "model_lag = Ridge(alpha=1.0)\n",
    "split = int(len(df_lagged) * 0.8)\n",
    "model_lag.fit(X_stage2_lag.iloc[:split], y_stage2_lag.iloc[:split])\n",
    "y_pred_lag = model_lag.predict(X_stage2_lag.iloc[split:])\n",
    "resid_lag = y_stage2_lag.iloc[split:] - y_pred_lag\n",
    "\n",
    "print(\"Test RMSE with lagged revenue:\",\n",
    "      mean_squared_error(y_stage2_lag.iloc[split:], y_pred_lag) ** 0.5)\n",
    "print(\"Test R² with lagged revenue:\",\n",
    "      r2_score(y_stage2_lag.iloc[split:], y_pred_lag))\n",
    "\n",
    "# Residuals vs predictions (after adding lags)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(y_pred_lag, resid_lag)\n",
    "plt.axhline(0, color='k', linestyle='--')\n",
    "plt.xlabel(\"Predicted revenue\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predictions (with lagged revenue)\")\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation of residuals\n",
    "plot_acf(resid_lag, lags=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b67bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Use the same features as Stage2 (without lagged revenue, since it hurt)\n",
    "X_gb = df[social_features + ['google_hat'] + controls]\n",
    "y_gb = df['revenue']\n",
    "\n",
    "# Time-based split\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X_gb.iloc[:split], X_gb.iloc[split:]\n",
    "y_train, y_test = y_gb.iloc[:split], y_gb.iloc[split:]\n",
    "\n",
    "# Fit Gradient Boosting\n",
    "gb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rmse_gb = mean_squared_error(y_test, y_pred_gb) ** 0.5\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"XGBoost Test RMSE: {rmse_gb:.2f}\")\n",
    "print(f\"XGBoost Test R²: {r2_gb:.3f}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test.values, label=\"Actual\")\n",
    "plt.plot(y_pred_gb, label=\"Predicted\")\n",
    "plt.title(\"XGBoost: Revenue (Test Set)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c849b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final XGBoost Model Training & SHAP Interpretation\n",
    "\n",
    "# 1. Import necessary libraries\n",
    "import shap\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Define features and target\n",
    "social_features = ['facebook_spend_sat', 'tiktok_spend_sat', 'snapchat_spend_sat', 'instagram_spend_sat']\n",
    "controls = ['emails_send','sms_send','social_followers','average_price','promotions']\n",
    "X_gb = df[social_features + ['google_hat'] + controls]\n",
    "y_gb = df['revenue']\n",
    "\n",
    "# 3. Split the data\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X_gb.iloc[:split], X_gb.iloc[split:]\n",
    "y_train, y_test = y_gb.iloc[:split], y_gb.iloc[split:]\n",
    "\n",
    "# 4. Define and train the XGBoost model\n",
    "gb_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    enable_categorical=True\n",
    ")\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Create a summary of the training data for the explainer's background dataset\n",
    "X_train_summary = shap.kmeans(X_train, 10)\n",
    "\n",
    "# 6. Create the KernelExplainer using a lambda function\n",
    "# This decouples the explainer from the main model object, avoiding the error\n",
    "prediction_function = lambda x: gb_model.predict(x)\n",
    "explainer = shap.KernelExplainer(prediction_function, X_train_summary)\n",
    "\n",
    "# 7. Calculate SHAP values for the test set\n",
    "# This will be slower, so please be patient\n",
    "print(\"Calculating SHAP values with KernelExplainer... (this may take a moment)\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "print(\"...done.\")\n",
    "\n",
    "# 8. Generate and display SHAP plots\n",
    "print(\"\\nSHAP Feature Importance (Bar Plot):\")\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSHAP Detailed Summary Plot:\")\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
